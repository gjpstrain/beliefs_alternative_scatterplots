---
format: acm-pdf

# use keep-tex to cause quarto to generate a .tex file
# which you can eventually use with TAPS

keep-tex: true

params:
  eval_models: false
  
knitr:
  opts_chunk: 
    cache_comments: false
    crop: true
    
execute: 
  echo: false
  warning: false
  message: false
  include: false

bibliography: atypical-scatterplots.bib

title: Changing Beliefs About Correlations in Atypical Scatterplots

# if short-title is defined, then it's used
short-title: 

author:
  - name: Gabriel Strain
    email: gabriel.strain@manchester.ac.uk
    orcid: 0000-0002-4769-9221
    affiliation:
      name: Department of Computer Science, Faculty of Science and Engineering, University of Manchester
      address: Oxford Road
      city: Manchester
      country: United Kingdom
      postal-code: M13 9PL
  - name: Andrew J. Stewart
    email: andrew.j.stewart@manchester.ac.uk
    affiliation:
      name: Department of Computer Science, Faculty of Science and Engineering, University of Manchester
      address: Oxford Road
      city: Manchester
      country: United Kingdom
      postal-code: M13 9PL
  - name: Paul Warren
    email: paul.warren@manchester.ac.uk
    affiliation:
      name: Division of Psychology, Communication and Human Neuroscience, School of Health Sciences, Faculty of Biology, Medicine, and Health, University of Manchester
      address: Oxford Road
      city: Manchester
      country: United Kingdom
      postal-code: M13 9PL
  - name: Charlotte Rutherford
    email: charlotte.rutherford-2@postgrad.manchester.ac.uk
    affiliation:
      name: Division of Psychology Communication and Human Neuroscience, School of Health Sciences, Faculty of Biology, Medicine, and Health, University of Manchester
      address: Oxford Road
      city: Manchester
      country: United Kingdom
      postal-code: M13 9PL
  - name: Caroline Jay
    affiliation:
      name: Department of Computer Science, Faculty of Science and Engineering, University of Manchester
      address: Oxford Road
      city: Manchester
      country: United Kingdom
      postal-code: M13 9PL

# acm-specific metadata
acm-metadata:
  # comment this out to make submission anonymous
  # anonymous: true

  # comment this out to build a draft version
  final: false

  # comment this out to specify detailed document options
  # acmart-options: sigconf, review  

  # acm preamble information
  copyright-year: 2018
  acm-year: 2018
  copyright: acmcopyright
  doi: XXXXXXX.XXXXXXX
  conference-acronym: "Conference acronym 'XX"
  conference-name: |
    Make sure to enter the correct
    conference title from your rights confirmation emai
  conference-date: June 03--05, 2018
  conference-location: Woodstock, NY
  price: "15.00"
  isbn: 978-1-4503-XXXX-X/18/06

  # if present, replaces the list of authors in the page header.
  shortauthors: Strain et al.

  # The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
  # Please copy and paste the code instead of the example below.
  ccs: |
    \begin{CCSXML}
    <ccs2012>
     <concept>
      <concept_id>10010520.10010553.10010562</concept_id>
      <concept_desc>Computer systems organization~Embedded systems</concept_desc>
      <concept_significance>500</concept_significance>
     </concept>
     <concept>
      <concept_id>10010520.10010575.10010755</concept_id>
      <concept_desc>Computer systems organization~Redundancy</concept_desc>
      <concept_significance>300</concept_significance>
     </concept>
     <concept>
      <concept_id>10010520.10010553.10010554</concept_id>
      <concept_desc>Computer systems organization~Robotics</concept_desc>
      <concept_significance>100</concept_significance>
     </concept>
     <concept>
      <concept_id>10003033.10003083.10003095</concept_id>
      <concept_desc>Networks~Network reliability</concept_desc>
      <concept_significance>100</concept_significance>
     </concept>
    </ccs2012>
    \end{CCSXML}
    
    \ccsdesc[500]{Computer systems organization~Embedded systems}
    \ccsdesc[300]{Computer systems organization~Redundancy}
    \ccsdesc{Computer systems organization~Robotics}
    \ccsdesc[100]{Networks~Network reliability}

  keywords:
    - belief change
    - correlation perception
    - scatterplot
    - crowdsourced
  
abstract: |
  abstract goes here

---

```{r}
#| label: setup

set.seed(1234) # random seed for number generation

library(tidyverse)
library(MASS)
library(emmeans)
library(scales)
library(buildmer)
library(lme4)
library(kableExtra)
library(papaja)
library(qwraps2)
library(lmerTest)
library(ggdist)
library(ggpubr)
library(conflicted)
library(ggtext)
library(r2glmm)
library(grid)
library(DescTools)
library(Matrix)
library(irr)

# fix conflicts now using the conflicted package

conflicts_prefer(dplyr::select(), dplyr::filter(), lme4::lmer(), DescTools::AUC())

```

```{r}
#| label: lazyload-cache

if (!params$eval_models){ lazyload_cache_dir("beliefs_attitudes_atypical_scatterplots_cache/pdf") }
```

```{r}
#| label: load-data

# load in data csvs for pre-test and main experiment

pre_test_anon <- read_csv("data/pre_test_response_final.csv")

main_exp_A <- read_csv("data/main_test_A.csv")

main_exp_T <- read_csv("data/main_test_T.csv")
```

```{r}
#| label: wrangle-data

## NB: With the exception of anonymization, data are provided as-is from 
## pavlovia (survey tool). Wrangling function *must* be run first to make
## the data set usable

wrangle_pre_test <- function(anon_file) {
  
# extract demographic information
  
demographics <- anon_file %>%
  filter(!is.na(gender_slider.response)) %>%
  select(matches(c("participant",
                   "age_textbox.text",
                   "gender_slider.response")))

time_taken <- anon_file %>%
  filter(!is.na(final.stopped)) %>%
  select(c("participant", "final.stopped"))
  

# select relevant columns
# select only experimental items
# change data types where appropriate
# output this file with suffix 'tidy'

anon_file %>%
  select(c("participant",
           "avg_corr",
           "avg_emot",
           "slider_emotion.response",
           "slider_belief.response",
           "statement",
           "item_no",
           "label",
           "session",
           )) %>%
  filter(item_no < 26) %>%
  full_join(demographics, by = "participant") %>%
  full_join(time_taken, by = "participant") %>%
  select(-c("__participant")) %>%
  assign(paste0(unique(anon_file$expName), "_tidy"),
           value = ., envir = .GlobalEnv)
}

wrangle_main_exp <- function(anon_file) {
  
# extract demographic information
  
demographics <- anon_file %>%
  filter(!is.na(gender_slider.response)) %>%
  select(matches(c("participant",
                   "age_textbox.text",
                   "gender_slider.response")))

time_taken <- anon_file %>%
  filter(!is.na(final.stopped)) %>%
  select(c("participant", "final.stopped"))

# extract literacy info

literacy <- anon_file %>%
    filter(!is.na(q5_slider.response)) %>%
    rowwise() %>%
    mutate(literacy = sum(c(q1_slider.response, 
                            q2_slider.response, 
                            q3_slider.response, 
                            q4_slider.response, 
                            q5_slider.response))) %>%
    select(participant,
           literacy)

# split unique item no column into number (dataset used) and letter (condition)

anon_file <- anon_file %>%
  separate(starts_with("unique"), into = c("item_no", "condition"), sep = "(?<=\\d)(?=\\D)") %>%
  mutate(belief_diff = slider_belief_post.response - slider_belief_pre.response)

# select relevant columns
# select only experimental items
# change data types where appropriate
# output this file with suffix 'tidy'

anon_file %>%
  select(c("participant",
           "item_no",
           "condition",
           "belief_diff",
           "slider_emotion.response",
           "slider.response",
           "trials.thisN"
           )) %>%
  mutate(half = case_when(
    trials.thisN < 23 ~ "first",
    trials.thisN > 23 ~ "second")) %>%
  filter(item_no < 46) %>%
  inner_join(literacy, by = "participant") %>%
  inner_join(demographics, by = "participant") %>%
  mutate(across(matches(c("item_no", "condition")), as_factor)) %>%
  mutate(trials.thisN = as.integer(trials.thisN)) %>%
  select(-c("__participant")) %>%
  assign(paste0(unique(anon_file$expName), "_tidy"),
           value = ., envir = .GlobalEnv)

}

# use wrangling function on anonymised data file

wrangle_pre_test(pre_test_anon)

mapply(wrangle_main_exp, main_exp_A, main_exp_T)

# check for missing age and gender id values

sum(is.na(beliefs_scatterplots_pretest_tidy$gender_slider.response))

sum(is.na(beliefs_scatterplots_pretest_tidy$age_textbox.text))

# missing age and gender values for a single participant
# print session with missing values

beliefs_scatterplots_pretest_tidy %>%
  filter(is.na(age_textbox.text)) %>%
  distinct(session)

# session id was used to look up age and gender identity and manually add
# this information to the final results csv using the prolific-supplied
# demographic information for the pretest
# this is not included as would expose personally identifiable prolific IDs

# Extract gender data into separate df

gender_pre <- distinct(beliefs_scatterplots_pretest_tidy, participant,
                      .keep_all = TRUE) %>%
  group_by(gender_slider.response) %>%
  summarise(perc = n()/nrow(.)*100) %>%
  pivot_wider(names_from = gender_slider.response, values_from = perc)

# extract age data into separate df

age_pre <- distinct(beliefs_scatterplots_pretest_tidy, participant,
                .keep_all = TRUE) %>%
  summarise(mean = mean(age_textbox.text, na.rm = TRUE),
            sd = sd(age_textbox.text, na.rm = TRUE)) 

# extract time taken data into separate dfs

time_taken_pre <- distinct(beliefs_scatterplots_pretest_tidy, participant,
                .keep_all = TRUE) %>%
  summarise(mean = mean(final.stopped/60, na.rm = TRUE),
            sd = sd(final.stopped/60, na.rm = TRUE)) 
```

```{r}
#| label: format-numbers-function

# function to format numbers when papaja prints them

add_and_to_numbers <- function(numbers) {

  num_str <- as.character(numbers)

  len <- length(num_str)
  
  if (len == 1) {

    return(num_str)
    
  } else if (len == 2) {
    
    return(paste(num_str[1], "and", num_str[2]))
    
  } else {

    return(paste(paste(num_str[1:(len-1)], collapse = ", "), ", and ", num_str[len], sep = ""))
  }
}

```

```{r}
#| label: author-pre-test-ratings

# NB: this code is reproduced here so that test values are accessible
# It can also be found at item_preparation/pre_test_stim.R

# Create dataframes for each rater

author_A_statements <- read_csv("item_preparation/statements_A.csv") %>%
  rename(Topic_Emotionality_A = Topic_Emotionality,
         Strength_of_Correlation_A = Strength_of_Correlation) %>%
  select(-Notes)
  

author_B_statements <- read_csv("item_preparation/statements_B.csv") %>%
  rename(Topic_Emotionality_B = Topic_Emotionality,
         Strength_of_Correlation_B = Strength_of_Correlation) %>%
  select(-Notes)

# Bind dataframes together

all_ratings <- left_join(author_A_statements,
                         author_B_statements,
                         by = c("Number",
                                "Statements"))

## IRR Calculations

irr_emot <- kappa2(matrix(c(all_ratings$Topic_Emotionality_A,
                all_ratings$Topic_Emotionality_B), ncol = 2), "squared")    

irr_corr <- kappa2(matrix(c(all_ratings$Strength_of_Correlation_A,
                all_ratings$Strength_of_Correlation_B), ncol = 2), "squared")    

```

# Introduction {#sec-intro-main}

# Related Work {#sec-rel-work-main}

# General Methods {#sec-general-methods}

In this section we discuss our general research methods, including our implementations
of open research practices, our approach to and justification for crowdsourcing, and our 
use of the ChatGPT4 LLM in preparing parts of our stimuli. 

## Open Research {#sec-open-research}

Both our pre and main studies were conducted according to the principles of open
and reproducible research [@ayris_2018]. We pre-registered hypotheses and analysis plans
with the Open Science Framework (OSF) for the pre-study[^1] and the main experiment[^2], and 
there were no deviations from them. All data and analysis code are included in a 
GitHub repository[^3]. This repository contains instructions for building a Docker
container [@merkel_2014] that reproduces the computational environment the paper
was written in. This allows for full replication of stimuli, figures, analysis,
and the paper itself. Ethical approval was granted by the (removed for anon).

[^1]: https://osf.io/xuf4d
[^2]: tbc
[^3]: https://github.com/gjpstrain/beliefs_attitudes_atypical

## Crowdsourcing

While much prior work into correlation perception in scatterplots has taken place
in person, there is precedence for work that explores cognition to take place
online using crowdsourced participants [@xiong_2022]. Crowdsourcing not only 
affords us recruitment of samples from across our lay population of interest,
it is considerably quicker and less expensive than in-person testing. We therefore choose
to crowdsource all participants. Previous work has reported issues of data quality
and skewed demographics [@chmielewski_2020; @charalambides_2021; @peer_2021], so
we follow published guidelines [@peer_2021] to give us the best chance of collecting
high quality data. We use the Prolific.co platform [@prolific] with strict pre-screening
criteria; participants were required to have completed at least 100 studies
using Prolific, and were required to have a Prolific score of 100, representing a 99%
approval rate.

## Use of Large Language Models

 - issues regarding stimulus generation normally
 - advantages conferred by using ChatGPT
 - reproducibility issues?

# Pre-Study: Investigating Beliefs About Relatedness Statements {#sec-pre-study}

## Introduction {#sec-pre-study-intro}

### Testing Beliefs {#sec-testing-beliefs}

### Preparation of Stimuli {#sec-stim-prep-pre}

Due to previous evidence suggesting effects of prior belief strength and topic
emotionality on the propensity for belief change, we first aim to build a
picture of people's thoughts and feelings along these dimensions in our
population of interest. With the intention of testing the potential for
changes in beliefs about correlations displayed in scatterplots depicting
weak and strong correlations, and those whose topics were both strong and
neutral in emotional valence, we began by using ChatGPT4 [@chatgpt] to
generate 100 correlation statements using the following prompt:

```{=tex}
\begin{center}

    ``Generate 100 statements that describe the correlation between two variables, such as :

     "X is associated with a higher level of Y" or

     "As X increases, Y increases".

    Try to match all the statements on emotionality.``
    
\end{center}
```

The full list of these statements can be found in the supplementary materials.
Note that we cite our use of ChatGPT according to the AI Code of Conduct developed
by Iliada Eleftheriou and Ajmal Mubarik and the University of Manchester
[@iliada_2023]. Two authors rated each statement on topic emotionality and
strength of correlation using Likert scales from 1 to 7. Topic emotionality
had a midpoint at 4, whereas strength of correlation varied between 1 (Not Related At All)
and 7 (Strongly Related). We calculated a quadratic weighted Cohen's Kappa
between the two raters using the **irr** package (version 0.84.1 [@irr]),
in order to penalise larger magnitude disagreements more harshly.
We found agreement above chance for both topic emotionality
($\kappa$ = `r printnum(irr_emot$value, digits = 2)`, *p* `r printp(irr_emot$p.value, add_equals = TRUE)`)
and strength of correlation ($\kappa$ = `r printnum(irr_corr$value, digits = 2)`,
*p* `r printp(irr_corr$p.value, add_equals = TRUE)`), indicating moderate 
levels of agreement in both cases [@cohen_1968; @fleiss_1969].

```{r}
#| label: tbl-pre-test-hi
#| include: true
#| tbl-cap: Pre-test statements that were rated as being strongly correlated.

# read in pre-test csv data

pre_test_statements_hi <- read_csv("data/pre_test_data.csv") %>%
  filter(label == "high_corr") %>%
  select(c("item_no","statement")) %>%
  rename("Statement - Strong Correlation Depicted" = "statement",
         "Item Number" = "item_no")

# make table

kbl(pre_test_statements_hi, booktabs = T)
```

```{r}
#| label: tbl-pre-test-low
#| include: true
#| tbl-cap: Pre-test statements that were rated as being weakly correlated.

# read in pre-test csv data

pre_test_statements_lo <- read_csv("data/pre_test_data.csv") %>%
  filter(label == "low_corr") %>%
  select(c("item_no","statement")) %>% 
  rename("Statement - Weak Correlation Depicted" = "statement",
         "Item Number" = "item_no")

# make table

kbl(pre_test_statements_lo, booktabs = T)
```

Following this, we selected strongly and weakly correlated statements with the
highest level of absolute agreement, resulting in the 14 strongly correlated
statements that can be seen in @tbl-pre-test-hi and the 11 weakly correlated
statements that can be seen in @tbl-pre-test-low. We then tested these 25
statements with a representative UK sample in order
to ascertain consensus on both topic emotionality and strength of correlation.
Doing so allows us to effectively exclude these factors when we analyse the effects
of our atypical scatterplot designs on the propensity for belief change
in our main experiment.

## Method {#sec-method-pre}

### Participants {#sec-participants-pre}

100 participants were recruited using the Prolific.co platform [@prolific]. English fluency and
residency was required for participation, as our main experiment relied on familiarity
with data visualisations from a popular British news source. In addition to 25
experimental items, we included six attention check items, which asked participants
to provide specific answers. No participants failed more than 2 out of 6 attention
check items, and therefore data from all 100 were included in the full analysis
(`r printnum(gender_pre$Male, digits = 1)`% male and `r printnum(gender_pre$Female, digits = 1)`% 
female. Participants' mean age was `r printnum(age_pre$mean, digits = 1)` (*SD* = 
`r printnum(age_pre$sd, digits = 1)`). The average time taken to complete the survey was
`r printnum(time_taken_pre$mean, digits = 1)` minutes (*SD* = `r printnum(time_taken_pre$sd, digits = 1)` minutes).

### Design {#sec-design-pre}

Each participant saw all survey items (@tbl-pre-test-hi and @tbl-pre-test-low),
along with the six attention check items, in a fully randomised order. All
experimental code, materials, and instructions are hosted on GitLab[^4].

[^4]: https://gitlab.pavlovia.org/Strain/beliefs_scatterplots_pretest

### Procedure {#sec-procedure-pre}

The experiment was built using Psychopy [@pierce_2019] and hosted on Pavlovia.org.
Participants were permitted to complete the experiment using a phone, tablet, desktop,
or laptop computer. Participants were first shown the participant information sheet
and were asked to provide consent through key presses in response to consent statements.
They were asked to provide their age in a free text box, followed by their 
gender identity. Participants were told that they would be asked to read statements
about the relatedness between a pair of variables, after which they would have to 
indicate their beliefs about topic emotionality and the strength of correlation suggested
using a pair of sliders. To familiarize themselves with the sliders, they were asked to complete a practice round
in response to the statement "As participation in online experiments increases,
society becomes happier."

## Results {#sec-results-pre}

```{r}
#| label: kappa-pre-test

# Calculate Fleiss' Kappa for 100 raters on emotional valence

pre_test_emot <- beliefs_scatterplots_pretest_tidy %>%
  select(c("participant", "slider_emotion.response", "item_no"))

emot_matrix <- xtabs(slider_emotion.response ~ item_no + participant, data = pre_test_emot)

emot_matrix <- as.matrix(emot_matrix)

emot_kappa <- kappam.fleiss(emot_matrix)

# do the same for strength of belief

pre_test_belief <- beliefs_scatterplots_pretest_tidy %>%
  select(c("participant", "slider_belief.response", "item_no"))

belief_matrix <- xtabs(slider_belief.response ~ item_no + participant, data = pre_test_belief)

belief_matrix <- as.matrix(belief_matrix)

belief_kappa <- kappam.fleiss(belief_matrix)

# calculate mean ratings and standard deviations for each statement

agreement_df_emot <- beliefs_scatterplots_pretest_tidy %>%
  group_by(item_no) %>%
  summarise(mean_emot = mean(slider_emotion.response),
            std_dev_emot = sd(slider_emotion.response)) %>%
  arrange(std_dev_emot)

agreement_df_belief <- beliefs_scatterplots_pretest_tidy %>%
  group_by(item_no) %>%
  summarise(mean_belief = mean(slider_belief.response),
            std_dev_belief = sd(slider_belief.response)) %>%
  arrange(std_dev_belief)

ratings_df <- full_join(agreement_df_belief, agreement_df_emot, by = "item_no")

# calculate average topic emotionality ratings

avg_emot <- ratings_df %>%
  filter(between(mean_emot, 3, 5))

# calculate consensus by summing standard deviations

consensus_df <- avg_emot %>%
  mutate(consensus = std_dev_belief + std_dev_emot) %>% 
  arrange(consensus) %>%
  slice_head(n =  2)
```

All analyses were conducted using R (version `r paste0(R.version$major, ".", R.version$minor)`).
We use the **irr** package to calculate Fleiss' Kappa to measure interrater agreement
on topic emotionality and strength of correlation for the 25 experimental items.
This analysis revealed that participants agreed above chance for both topic emotionality
($\kappa$ = `r printnum(emot_kappa$value, digits = 2)`, *p* `r printp(emot_kappa$p.value, add_equals = TRUE)`)
and strength of correlation ($\kappa$ = `r printnum(belief_kappa$value, digits = 2)`,
*p* `r printp(belief_kappa$p.value, add_equals = TRUE)`).

## Selecting Statements for the Main Experiment

To control for any potential effects of topic emotionality in the main experiment,
we first select statements that represent neutral emotional valence. Statements
with average topic emotionality ratings between 3 and 5 are statements 
`r printnum(add_and_to_numbers(avg_emot$item_no), digits = 0)`. To ascertain
which statements represent the greatest consensus, we add standard deviations in
ratings for topic emotionality and strength of correlation. Due to concerns about experimental
power, and in line with evidence that propensity for belief change is highest
when prior beliefs are not strongly held [@xiong_2022],
we elected at this point to test only the statement corresponding to weak beliefs
about the strength of correlation between the variables in question. We therefore
test statement number `r printnum(add_and_to_numbers(consensus_df$item_no[2]), digits = 0)`,
"Higher consumption of spicy foods is associated with a lower risk of certain types of cancer.",
however we modify the wording so that both variables (food consumption and cancer risk)
are positively correlated, as previous work indicates that the manipulations we use
in the atypical scatterplot condition are able to change estimates of correlation
in positively correlated scatterplots; no work regarding the effects of these
manipulations in negatively correlated scatterplots has been completed.

## Discussion {#sec-discussion-pre}

Fleiss' Kappa values for interrater agreement on both topic emotionality
and strength of correlation scales are low ($\kappa$ = `r printnum(emot_kappa$value, digits = 2)`
and $\kappa$ = `r printnum(belief_kappa$value, digits = 2)` respectively),
however do exceed that which would be expected by chance. We suggest this may be
due to Fleiss' Kappa not being designed with ordinal (Likert scales in this case) data in mind.
In light of this we do not make decisions regarding which statement to use based 
on the values of Fleiss' Kappa observed, but rather on the standard deviations of 
ratings across all raters. Regardless, we do not consider this to be a particular
weakness, as we also test topic emotionality and strength of correlation with participants
in the main study and include these ratings as part of our analysis.

# Main Study: Potential for Belief Change Using Atypical Scatterplots {#sec-main-study}

We test the statement that exhibited the lowest average level of belief about
correlation, and the 2nd highest level of consensus. Modified for directionality,
this statement is therefore: "Higher consumption of plain (non-spicy) foods
is associated with a lower risk of certain types of cancer."

## Introduction

 - hypotheses
 - 

### Defensive Confidence

In line with evidence that those who are more confident in their ability to defend
their own positions are more susceptible to having those positions changed [@albarracin_2004],
we test participants' defensive confidence using a 12-item scale. This scale is 
replicated from previous work in the supplemental material, and has additionally
been utilized more recently [@markant_2023] to explore the potential for attitude
change specifically with regards to correlations in scatterplots. Participants
provide answers to the 12 scale items using a 5 point Likert scale ranging from 1
(*not at all characteristic of me*) to 5 (*extremely characteristic of me*).

- don't forget about reverse scoring items

## Stimuli

- build experiment and pilot to see how many people can do 
- then this section can be written

## Method

### Participants

Participants were recruited using Prolific.co [@prolific]. English fluency and UK
residency was required for participation, as well as normal or corrected-to-normal
vision, and having not participated in any of our previous studies regarding 
correlation perception in scatterplots, as these represented earlier testing 
of the alternative designs we employ in the atypical scatterplot condition. In addition
to 45(?) experimental items, we also included 6 attention check trials...

### Design

We employ a between-participants design. Each participants was randomly assigned
to either group A, in which case they viewed typical scatterplots, or group B,
in which they viewed atypical scatterplots designed deliberately to elicit higher
levels of belief change.

### Procedure

Again, we use PsychoPy [@pierce_2019] to build our experiment and Pavlovia.org
to host it. Participants were permitted to complete the experiment on a desktop
or laptop computer. We elected to prevent participants from using a phone or
tablet to complete the experiment in line with evidence that differences in on-screen sizes
of data visualizations can alter perception [cleveland_1982]. Participants were
first shown the participant information sheet and asked to provide consent
through key presses in response to consent statements. They were, again,
asked to provide their age and gender identity. Participants then completed the 12-item
Defensive Confidence scale described by Albarracín and Mitchell [@albarracin_2004].
Following instructions, which included descriptions of scatterplots and Pearson's *r*.
In order to give legitimacy to our data visualizations with the hope of maximising
any potential belief change, participants were told that the graphs were taken
from a well-known British news source, but that the identity of this source had 
been obscured. They then had a chance to practice using the slider, before being 
asked their belief about topic emotionality and the relatedness between variables
described in our chosen statement. Following the completion of 45(?) experimental
trials, participants were tested again on their beliefs about relatedness, and 
then debriefed that the data they saw were fictional.

## Results

## Discussion

# General Discussion

# Limitations

# Future Work

# Conclusion

# References {.unnumbered}
