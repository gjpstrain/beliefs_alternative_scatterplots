---
format: acm-pdf

# use keep-tex to cause quarto to generate a .tex file
# which you can eventually use with TAPS
keep-tex: true

params:
  eval_models: false
  
knitr:
  opts_chunk: 
    cache_comments: false
    crop: true
    
execute: 
  echo: false
  warning: false
  message: false
  include: false

bibliography: atypical-scatterplots.bib

title: Changing Beliefs About Correlations in Atypical Scatterplots

# if short-title is defined, then it's used
short-title: 

author:
  - name: Gabriel Strain
    email: gabriel.strain@manchester.ac.uk
    orcid: 0000-0002-4769-9221
    affiliation:
      name: Department of Computer Science, Faculty of Science and Engineering, University of Manchester
      address: Oxford Road
      city: Manchester
      country: United Kingdom
      postal-code: M13 9PL
  - name: Andrew J. Stewart
    email: andrew.j.stewart@manchester.ac.uk
    affiliation:
      name: Department of Computer Science, Faculty of Science and Engineering, University of Manchester
      address: Oxford Road
      city: Manchester
      country: United Kingdom
      postal-code: M13 9PL
  - name: Paul Warren
    email: paul.warren@manchester.ac.uk
    affiliation:
      name: Division of Psychology, Communication and Human Neuroscience, School of Health Sciences, Faculty of Biology, Medicine, and Health, University of Manchester
      address: Oxford Road
      city: Manchester
      country: United Kingdom
      postal-code: M13 9PL
  - name: Charlotte Rutherford
    email: charlotte.rutherford-2@postgrad.manchester.ac.uk
    affiliation:
      name: Division of Psychology Communication and Human Neuroscience, School of Health Sciences, Faculty of Biology, Medicine, and Health, University of Manchester
      address: Oxford Road
      city: Manchester
      country: United Kingdom
      postal-code: M13 9PL
  - name: Caroline Jay
    affiliation:
      name: Department of Computer Science, Faculty of Science and Engineering, University of Manchester
      address: Oxford Road
      city: Manchester
      country: United Kingdom
      postal-code: M13 9PL

# acm-specific metadata
acm-metadata:
  # comment this out to make submission anonymous
  # anonymous: true

  # comment this out to build a draft version
  final: false

  # comment this out to specify detailed document options
  # acmart-options: sigconf, review  

  # acm preamble information
  copyright-year: 2018
  acm-year: 2018
  copyright: acmcopyright
  doi: XXXXXXX.XXXXXXX
  conference-acronym: "Conference acronym 'XX"
  conference-name: |
    Make sure to enter the correct
    conference title from your rights confirmation emai
  conference-date: June 03--05, 2018
  conference-location: Woodstock, NY
  price: "15.00"
  isbn: 978-1-4503-XXXX-X/18/06

  # if present, replaces the list of authors in the page header.
  shortauthors: Strain et al.

  # The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
  # Please copy and paste the code instead of the example below.
  ccs: |
    \begin{CCSXML}
    <ccs2012>
     <concept>
      <concept_id>10010520.10010553.10010562</concept_id>
      <concept_desc>Computer systems organization~Embedded systems</concept_desc>
      <concept_significance>500</concept_significance>
     </concept>
     <concept>
      <concept_id>10010520.10010575.10010755</concept_id>
      <concept_desc>Computer systems organization~Redundancy</concept_desc>
      <concept_significance>300</concept_significance>
     </concept>
     <concept>
      <concept_id>10010520.10010553.10010554</concept_id>
      <concept_desc>Computer systems organization~Robotics</concept_desc>
      <concept_significance>100</concept_significance>
     </concept>
     <concept>
      <concept_id>10003033.10003083.10003095</concept_id>
      <concept_desc>Networks~Network reliability</concept_desc>
      <concept_significance>100</concept_significance>
     </concept>
    </ccs2012>
    \end{CCSXML}
    
    \ccsdesc[500]{Computer systems organization~Embedded systems}
    \ccsdesc[300]{Computer systems organization~Redundancy}
    \ccsdesc{Computer systems organization~Robotics}
    \ccsdesc[100]{Networks~Network reliability}

  keywords:
    - belief change
    - correlation perception
    - scatterplot
    - crowdsourced
  
abstract: |
  abstract goes here

---

```{r}
#| label: setup

set.seed(1234) # random seed for number generation

library(tidyverse)
library(MASS)
library(emmeans)
library(scales)
library(buildmer)
library(lme4)
library(kableExtra)
library(papaja)
library(qwraps2)
library(lmerTest)
library(ggdist)
library(ggpubr)
library(conflicted)
library(ggtext)
library(r2glmm)
library(grid)
library(DescTools)
library(Matrix)
library(irr)

# fix conflicts now using the conflicted package

conflicts_prefer(dplyr::select(), dplyr::filter(), lme4::lmer(), DescTools::AUC())

```

```{r}
#| label: lazyload-cache

if (!params$eval_models){ lazyload_cache_dir("beliefs_attitudes_atypical_scatterplots_cache/pdf") }
```

```{r}
#| label: load-data

# load in data csvs for pre-test and main experiment

pre_test_anon <- read_csv("data/pre_test_response_final.csv")
```

```{r}
#| label: wrangle-data

## NB: With the exception of anonymization, data are provided as-is from 
## pavlovia (survey tool). Wrangling function *must* be run first to make
## the data set usable

wrangle_pre_test <- function(anon_file) {
  
# extract demographic information
  
demographics <- anon_file %>%
  filter(!is.na(gender_slider.response)) %>%
  select(matches(c("participant",
                   "age_textbox.text",
                   "gender_slider.response")))

time_taken <- anon_file %>%
  filter(!is.na(final.stopped)) %>%
  select(c("participant", "final.stopped"))
  

# select relevant columns
# select only experimental items
# change data types where appropriate
# output this file with suffix 'tidy'

anon_file %>%
  select(c("participant",
           "avg_corr",
           "avg_emot",
           "slider_emotion.response",
           "slider_belief.response",
           "statement",
           "item_no",
           "label",
           "session",
           )) %>%
  filter(item_no < 26) %>%
  full_join(demographics, by = "participant") %>%
  full_join(time_taken, by = "participant") %>%
  select(-c("__participant")) %>%
  assign(paste0(unique(anon_file$expName), "_tidy"),
           value = ., envir = .GlobalEnv)
}

# use wrangling function on anonymised data file

wrangle_pre_test(pre_test_anon)

# check for missing age and gender id values

sum(is.na(beliefs_scatterplots_pretest_tidy$gender_slider.response))

sum(is.na(beliefs_scatterplots_pretest_tidy$age_textbox.text))

# missing age and gender values for a single participant
# print session with missing values

beliefs_scatterplots_pretest_tidy %>%
  filter(is.na(age_textbox.text)) %>%
  distinct(session)

# session id was used to look up age and gender identity and manually add
# this information to the final results csv using the prolific-supplied
# demographic information for the pretest
# this is not included as would expose personally identifiable prolific IDs

# Extract gender data into separate df

gender_pre <- distinct(beliefs_scatterplots_pretest_tidy, participant,
                      .keep_all = TRUE) %>%
  group_by(gender_slider.response) %>%
  summarise(perc = n()/nrow(.)*100) %>%
  pivot_wider(names_from = gender_slider.response, values_from = perc)

# extract age data into separate df

age_pre <- distinct(beliefs_scatterplots_pretest_tidy, participant,
                .keep_all = TRUE) %>%
  summarise(mean = mean(age_textbox.text, na.rm = TRUE),
            sd = sd(age_textbox.text, na.rm = TRUE)) 

# extract time taken data into separate dfs

time_taken_pre <- distinct(beliefs_scatterplots_pretest_tidy, participant,
                .keep_all = TRUE) %>%
  summarise(mean = mean(final.stopped/60, na.rm = TRUE),
            sd = sd(final.stopped/60, na.rm = TRUE)) 
```

```{r}
#| label: format-numbers-function

add_and_to_numbers <- function(numbers) {

  num_str <- as.character(numbers)

  len <- length(num_str)
  
  if (len == 1) {

    return(num_str)
    
  } else if (len == 2) {
    
    return(paste(num_str[1], "and", num_str[2]))
    
  } else {

    return(paste(paste(num_str[1:(len-1)], collapse = ", "), ", and ", num_str[len], sep = ""))
  }
}

```

```{r}
#| label: author-pre-test-ratings

# NB: this code is reproduced here so that test values are accessible
# It can also be found at item_preparation/pre_test_stim.R

# Create dataframes for each rater

author_A_statements <- read_csv("item_preparation/statements_A.csv") %>%
  rename(Topic_Emotionality_A = Topic_Emotionality,
         Strength_of_Correlation_A = Strength_of_Correlation) %>%
  select(-Notes)
  

author_B_statements <- read_csv("item_preparation/statements_B.csv") %>%
  rename(Topic_Emotionality_B = Topic_Emotionality,
         Strength_of_Correlation_B = Strength_of_Correlation) %>%
  select(-Notes)

# Bind dataframes together

all_ratings <- left_join(author_A_statements,
                         author_B_statements,
                         by = c("Number",
                                "Statements"))

## IRR Calculations

irr_emot <- kappa2(matrix(c(all_ratings$Topic_Emotionality_A,
                all_ratings$Topic_Emotionality_B), ncol = 2), "squared")    

irr_corr <- kappa2(matrix(c(all_ratings$Strength_of_Correlation_A,
                all_ratings$Strength_of_Correlation_B), ncol = 2), "squared")    

```

# Introduction {#sec-intro-main}

# Related Work {#sec-rel-work-main}

# General Methods {#sec-general-methods}

In this section we discuss our general research methods, including our implementations
of open research practices, our approach to and justification for crowdsourcing, 
and our approach to stimulus generation.

## Open Research {#sec-open-research}

Both our pre and main studies were conducted according to the principles of open
and reproducible research [@ayris_2018]. We pre-registered hypotheses and analysis plans
with the Open Science Framework (OSF) for the pre-study[^1] and the main experiment[^2], and 
there were no deviations from them. All data and analysis code are included in a 
GitHub repository[^3]. This repository contains instructions for building a Docker
container [@merkel_2014] that reproduces the computational environment the paper
was written in. This allows for full replication of stimuli, figures, analysis,
and the paper itself. Ethical approval was granted the (removed for anon).

[^1]: https://osf.io/xuf4d
[^2]: tbc
[^3]: https://github.com/gjpstrain/beliefs_attitudes_atypical

# Pre-Study: Investigating Beliefs About Relatedness Statements {#sec-pre-study}

## Introduction {#sec-pre-study-intro}

### Testing Beliefs {#sec-testing-beliefs}

### Preparation of Stimuli {#sec-stim-prep-pre}

Due to previous evidence suggesting effects of prior belief strength and topic
emotionality on the propensity for belief change, we first aim to build a
picture of people's thoughts and feelings along these dimensions in our
population of interest. With the intention of testing the potential for
changes in beliefs about correlations displayed in scatterplots depicting
weak and strong correlations, and those whose topics were both strong and
neutral in emotional valence, we began by using ChatGPT4 [@chatgpt] to
generate 100 correlation statements using the following prompt:

```{=tex}
\begin{center}

    ``Generate 100 statements that describe the correlation between two variables, such as :

     "X is associated with a higher level of Y" or

     "As X increases, Y increases".

    Try to match all the statements on emotionality.``
    
\end{center}
```

The full list of these statements can be found in the supplementary materials.
Note that we cite our use of ChatGPT according to the AI Code of Conduct developed
by Iliada Eleftheriou and Ajmal Mubarik and the University of Manchester
[@iliada_2023]. Two authors rated each statement on topic emotionality and
strength of correlation using Likert scales from 1 to 7. Topic emotionality
had a midpoint at 4, whereas strength of correlation varied between 1 (Not Related At All)
and 7 (Strongly Related). We calculated a quadratic weighted Cohen's Kappa
between the two raters using the **irr** package (version 0.84.1 [@irr]),
in order to penalise larger magnitude disagreements more harshly.
We found agreement above chance for both topic emotionality
($\kappa$ = `r printnum(irr_emot$value, digits = 2)`, *p* `r printp(irr_emot$p.value, add_equals = TRUE)`)
and strength of correlation ($\kappa$ = `r printnum(irr_corr$value, digits = 2)`,
*p* `r printp(irr_corr$p.value, add_equals = TRUE)`), indicating moderate 
levels of agreement in both cases [@cohen_1968; @fleiss_1969].

```{r}
#| label: tbl-pre-test-hi
#| include: true
#| tbl-cap: Pre-test statements that were rated as being strongly correlated.

# read in pre-test csv data

pre_test_statements_hi <- read_csv("data/pre_test_data.csv") %>%
  filter(label == "high_corr") %>%
  select(c("item_no","statement")) %>%
  rename("Statement - Strong Correlation Depicted" = "statement",
         "Item Number" = "item_no")

# make table

kbl(pre_test_statements_hi, booktabs = T)
```

```{r}
#| label: tbl-pre-test-low
#| include: true
#| tbl-cap: Pre-test statements that were rated as being weakly correlated.

# read in pre-test csv data

pre_test_statements_lo <- read_csv("data/pre_test_data.csv") %>%
  filter(label == "low_corr") %>%
  select(c("item_no","statement")) %>% 
  rename("Statement - Weak Correlation Depicted" = "statement",
         "Item Number" = "item_no")

# make table

kbl(pre_test_statements_lo, booktabs = T)
```

Following this, we selected strongly and weakly correlated statements with the
highest level of absolute agreement, resulting in the 14 strongly correlated
statements that can be seen in @tbl-pre-test-hi and the 11 weakly correlated
statements that can be seen in @tbl-pre-test-low. As we only needed two statements
for each of the high and low correlation conditions in our main experiment, 
we elected to test these 25 statements with a representative UK sample in order
to ascertain consensus on both topic emotionality and strength of correlation.
Doing so allows us to effectively exclude these factors when we analyse the effects
of our atypical scatterplot designs on the propensity for belief change
in our main experiment.

## Method {#sec-method-pre}

### Participants {#sec-participants-pre}

100 participants were recruited using the Prolific.co platform [@prolific]. English fluency and
residency was required for participation, as our main experiment relied on familiarity
with data visualisations from a popular British news source. In addition to 25
experimental items, we included six attention check items, which asked participants
to provide specific answers. No participants failed more than 2 out of 6 attention
check items, and therefore data from all 100 were included in the full analysis
(`r printnum(gender_pre$Male, digits = 1)`% male and `r printnum(gender_pre$Female, digits = 1)`% 
female. Participants' mean age was `r printnum(age_pre$mean, digits = 1)` (*SD* = 
`r printnum(age_pre$sd, digits = 1)`). The average time taken to complete the survey was
`r printnum(time_taken_pre$mean, digits = 1)` minutes (*SD* = `r printnum(time_taken_pre$sd, digits = 1)` minutes).

### Design {#sec-design-pre}

Each participant saw all survey items (@tbl-pre-test-hi and @tbl-pre-test-low),
along with the six attention check items, in a fully randomised order. All
experimental code, materials, and instructions are hosted on GitLab[^4].

[^4]: https://gitlab.pavlovia.org/Strain/beliefs_scatterplots_pretest

### Procedure {#sec-procedure-pre}

The experiment was built using Psychopy [@pierce_2019] and hosted on Pavlovia.org.
Participants were permitted to complete the experiment using a phone, tablet, desktop,
or laptop computer. Participants were first shown the participant information sheet
and were asked to provide consent through key presses in response to consent statements.
They were asked to provide their age in a free text box, followed by their 
gender identity. Participants were told that they would be asked to read statements
about the relatedness between a pair of variables, after which they would have to 
indicate their beliefs about topic emotionality and the strength of correlation suggested.
To familiarize themselves with the slider, they were asked to complete a practice round
in response to the statement "As participation in online experiments increases,
society becomes happier."

## Results {#sec-results-pre}

```{r}
#| label: kappa-pre-test

# Calculate Fleiss' Kappa for 100 raters on emotional valence

pre_test_emot <- beliefs_scatterplots_pretest_tidy %>%
  select(c("participant", "slider_emotion.response", "item_no"))

emot_matrix <- xtabs(slider_emotion.response ~ item_no + participant, data = pre_test_emot)

emot_matrix <- as.matrix(emot_matrix)

emot_kappa <- kappam.fleiss(emot_matrix)

# do the same for strength of belief

pre_test_belief <- beliefs_scatterplots_pretest_tidy %>%
  select(c("participant", "slider_belief.response", "item_no"))

belief_matrix <- xtabs(slider_belief.response ~ item_no + participant, data = pre_test_belief)

belief_matrix <- as.matrix(belief_matrix)

belief_kappa <- kappam.fleiss(belief_matrix)

# calculate mean ratings and standard deviations for each statement

agreement_df_emot <- beliefs_scatterplots_pretest_tidy %>%
  group_by(item_no) %>%
  summarise(mean_emot = mean(slider_emotion.response),
            std_dev_emot = sd(slider_emotion.response)) %>%
  arrange(std_dev_emot)

agreement_df_belief <- beliefs_scatterplots_pretest_tidy %>%
  group_by(item_no) %>%
  summarise(mean_belief = mean(slider_belief.response),
            std_dev_belief = sd(slider_belief.response)) %>%
  arrange(std_dev_belief)

ratings_df <- full_join(agreement_df_belief, agreement_df_emot, by = "item_no")

# calculate average topic emotionality ratings

avg_emot <- ratings_df %>%
  filter(between(mean_emot, 3, 5))

# calculate consensus by summing standard deviations

consensus_df <- avg_emot %>%
  mutate(consensus = std_dev_belief + std_dev_emot) %>% 
  arrange(consensus) %>%
  slice_head(n = 2)
```

All analyses were conducted using R (version `r paste0(R.version$major, ".", R.version$minor)`).
We use the **irr** package to calculate Fleiss' Kappa to measure interrater agreement
on topic emotionality and strength of correlation for the 25 experimental items.
This analysis revealed that participants agreed above chance for both topic emotionality
($\kappa$ = `r printnum(emot_kappa$value, digits = 2)`, *p* `r printp(emot_kappa$p.value, add_equals = TRUE)`)
and strength of correlation ($\kappa$ = `r printnum(belief_kappa$value, digits = 2)`,
*p* `r printp(belief_kappa$p.value, add_equals = TRUE)`).

## Selecting Statements for the Main Experiment

To control for any potential effects of topic emotionality in the main experiment,
we first select statements that represent neutral emotional valence. Statements
with average topic emotionality ratings between 3 and 5 are statements 
`r printnum(add_and_to_numbers(avg_emot$item_no), digits = 0)`. To ascertain
which statements represent the greatest consensus, we add standard deviations in
ratings for topic emotionality and strength of correlation, then take the statement
from each of the high and low correlation lists with the lowest summed standard
deviation, which in this case is statements `r printnum(add_and_to_numbers(consensus_df$item_no), digits = 0)`
(see @tbl-pre-test-hi and @tbl-pre-test-low). In order to control for statement
directionality, the wording of statement `r printnum(add_and_to_numbers(consensus_df$item_no[2]), digits = 0)`
is changed; the final statements can be see in @sec-main-study.

## Discussion {#sec-discussion-pre}

Fleiss' Kappa values for interrater agreement on both topic emotionality
and strength of correlation scales are low ($\kappa$ = `r printnum(emot_kappa$value, digits = 2)`
and$\kappa$ = `r printnum(belief_kappa$value, digits = 2)` respectively),
however do exceed that which would be expected by chance. We suggest this may be
due to Fleiss' Kappa not being designed with ordinal (Likert scales in this case) data in mind.
In light of this we do not make decisions regarding which statements to use based 
on the values of Fleiss' Kappa observed, but rather on the standard deviations of 
ratings across all raters. Regardless, we do not consider this to be a particular
weakness, as we also test topic emotionality and strength of correlation with participants
in the main study and include these ratings as part of our analysis.

# Main Study: Potential for Belief Change Using Atypical Scatterplots {#sec-main-study}



## Introduction

## Method

### Participants

### Design

### Procedure

## Results

## Discussion

# General Discussion

# Limitations

# Future Work

# Conclusion

# References {.unnumbered}
